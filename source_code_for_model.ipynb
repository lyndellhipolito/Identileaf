{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP5FrtP4SFSn"
      },
      "outputs": [],
      "source": [
        "# DIRECTORY STRUCTURE\n",
        "# household_plants/\n",
        "#     train/\n",
        "#         bangkok kalachuchi/\n",
        "#         jade plant/\n",
        "#         neon pothos/\n",
        "#         philodendron birkin/\n",
        "#         red beauty aglaonema/\n",
        "# \n",
        "#     test/\n",
        "#         bangkok kalachuchi/\n",
        "#         jade plant/\n",
        "#         neon pothos/\n",
        "#         philodendron birkin/\n",
        "#         red beauty aglaonema/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvaZuXcLUydP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnIcrVOSXxKC",
        "outputId": "7939db46-0ff0-48d8-b427-c18cb6f964c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTtxwOhmVmqZ"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/household_plants.zip', 'r')\n",
        "zip_ref.extractall('/full_dataset')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8CJc_ahzbZS"
      },
      "source": [
        "### **INITIALIZE VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wva7fcPBYYLY"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "train_data_dir = '/full_dataset/household_plants/train'\n",
        "validation_data_dir = '/full_dataset/household_plants/test'\n",
        "\n",
        "total_samples = 750\n",
        "train_split, test_split = .80, .20\n",
        "nb_train_samples = total_samples * train_split\n",
        "nb_validation_samples = total_samples * test_split\n",
        "input_shape = (img_width, img_height, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OJACSZO3ISz"
      },
      "source": [
        "### **DATA AUGMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzOuI3X90YBU"
      },
      "outputs": [],
      "source": [
        "# rescale standardizes data (if you dont, training time increases and result may not be accurate)\n",
        "# data augmentation is important to prevent overfitting and to add variance to the training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=8,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtL-3lr62dL7"
      },
      "outputs": [],
      "source": [
        "# flow_from_directory makes it so that the name of the \n",
        "# subdirectory are the labels\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    seed=123)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    seed=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XOcaoTIsxLt"
      },
      "outputs": [],
      "source": [
        "classes = train_generator.class_indices\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Q_8ML_eH3f"
      },
      "source": [
        "### **CREATE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svtANT3bmrHd"
      },
      "outputs": [],
      "source": [
        "num_classes = len(classes)\n",
        "model = Sequential([\n",
        "  # input layer + hidden layer 1\n",
        "  Dense(units=64, input_shape=input_shape, activation='relu'),\n",
        "\n",
        "  # hidden layer 2\n",
        "  Dense(units=32, activation='relu'),\n",
        "  Flatten(),                                  \n",
        "\n",
        "  # output layer \n",
        "  Dense(num_classes, activation='softmax')                                  \n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr1hJqdmTTgK"
      },
      "source": [
        "### **INITIALIZING HYPERPARAMETERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QayVUsa7gGIq"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lD4pcrmmVxz"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH4BcurR0zQy"
      },
      "source": [
        "### **TRAINING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zePkqI2RgTha"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "class TimingCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, logs={}):\n",
        "        self.logs=[]\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.starttime = timer()\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(timer()-self.starttime)\n",
        "\n",
        "get_training_time = TimingCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReHrU5_4mmSA"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "bst_model_path = 'best-model.h5'\n",
        "mcp_save = ModelCheckpoint(bst_model_path,                                              # saves best model observed during training\n",
        "                           monitor='val_loss', verbose=1, save_best_only=True,          \n",
        "                           restore_best_weights=True)\n",
        "                                   \n",
        "hist = model.fit(\n",
        "      train_generator,\n",
        "      validation_data=validation_generator,\n",
        "      epochs=epochs,\n",
        "      steps_per_epoch=nb_train_samples // batch_size,                                   # specifies the total number of steps as soon as one epoch is finished and next epoch has started\n",
        "      validation_steps=nb_validation_samples // batch_size,\n",
        "      callbacks=[mcp_save, get_training_time]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5gOwljDgfu6"
      },
      "outputs": [],
      "source": [
        "print(get_training_time.logs)\n",
        "print(f'{sum(get_training_time.logs)/60:.2f} minutes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYzhDdcEYhqr"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl8Us-7NVa4n"
      },
      "source": [
        "### **VISUALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUMA6baW1Y9Y"
      },
      "outputs": [],
      "source": [
        "train_score = model.evaluate(train_generator, verbose=1)\n",
        "test_score = model.evaluate(validation_generator, verbose=1)\n",
        "\n",
        "print()\n",
        "print('TRAINING SET')\n",
        "print(f'[INFO] Accuracy: {train_score[1] * 100:.2f}')\n",
        "print(f'[INFO] Loss: {train_score[0]}')\n",
        "print()\n",
        "print('TESTING SET')\n",
        "print(f'[INFO] Accuracy: {test_score[1] * 100:.2f}')\n",
        "print(f'[INFO] Loss: {test_score[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z215FmOjBixc"
      },
      "outputs": [],
      "source": [
        "epochs = len(hist.history['loss']) # get epochs after early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-To2NO981UYp"
      },
      "outputs": [],
      "source": [
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0qNFzzSVRAZ"
      },
      "source": [
        "### **CONFUSION MATRIX #1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pxyTgLHU8v6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "target_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "# get confusion matrix\n",
        "Y_pred = model.predict(validation_generator, nb_validation_samples // batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "cf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
        "\n",
        "# print classification report\n",
        "print('Classification Report')\n",
        "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SXeQl1f1KlH"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ['bangkok kalachuchi', 'jade plant', 'neon pothos', 'philodendron birkin', 'red beauty aglaonema']\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                cf_matrix.flatten()]\n",
        "\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "\n",
        "labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
        "          zip(group_counts,group_percentages)]\n",
        "\n",
        "labels = np.asarray(labels).reshape(5,5)\n",
        "ax = sns.heatmap(cf_matrix, annot=labels, fmt='')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Houseplant')\n",
        "ax.set_ylabel('Actual Houseplant');\n",
        "\n",
        "ax.xaxis.set_ticklabels(classes, rotation=45)\n",
        "ax.yaxis.set_ticklabels(classes, rotation=45)\n",
        "\n",
        "# displays confusion matrix\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}